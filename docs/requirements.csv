Item,,,,Produced by:,Michael Gangl,MDPS,,,
Level 1,,,,on:,12/14/23,JPL,,,
Parent,ID,Level,Name,Rationale,VnV Method,VnV Approach,Tags,VnV Component,VnV Feature
,MDPS_L1_REQ-1,L1,"The MDPS project shall provide a platform to process, store, manage, and provide access to science data products.","The processing of science data into science products is a primary goal of the MDPS. This applies to multiple project types: flight, R&A, outreach, formulation projects for earth, planetary, and solar system; Storing and managing the data enable data product reproducability and discovery.
 
 
   
 
 
  The science products can be standard, reprocessed, or bespoke- there is no requirement on what type of products can be generated.",,,eso-prototype,,
,MDPS_L1_REQ-2,L1,"The MDPS project shall provide a platform to develop, test, and validate product generation algorithms in an operations-like environment.","""Requirement enables faster algorithm development, test, and validation via fewer hand offs and complete self servicing (automated algorithm packaging, ability to run in an ops like SDS without hand offs). This applies to multiple project types: flight, R&A, outreach, formulation projects for earth, planetary, and solar system;
 
 
 
 Development: initial creation and improvements of software algorithms
 
 Test: unit and system integration into an ops like environment
 
 Validate: Analysis of test or production generated data products, visualization of products, comparisons to other known data (e.g. Cal/Val), matchup services""",,,eso-prototype,,
,MDPS_L1_REQ-3,L1,The MDPS project shall provide a platform for use by three or more projects,"The MDPS science data system is a singular platform with multiple instances of project based functionality. That is, many projects can use the MDPS, but many of the managed services will be specific to the project and venue of that project.
 
 
   
 
 
  Formerly a multi-tenant requirement;
 
 
   
 
 
  We also specify 3 (as a minimum ) projects to drive requirements for eventual MMO Staffing, support, and design of the system.",,,eso-prototype,,
,MDPS_L1_REQ-4,L1,The MDPS project shall provide a platform comprised of managed services.,"This will minimize setup time, resources, and workforce needed to spin up and make services available.
 
 
   
 
 
  Managed services are a systematic way of deploying, upgrading, and removing a service.",,,eso-prototype,,
,MDPS_L1_REQ-5,L1,The MDPS shall enable open science through compliance with SPD-41a and ESD-specific open science policies.,"The main tenants of Open Science MDPS seeks to fulfill are:
 
 
 
 Open methodology - sharing of Algorithm Theoretical Basis Documents, provenance, reproducability
 
 Open source - Share code and processing
 
 Open data - Share data and results
 
 Open access - access to data where not strictly prohibited
 
 Open educational resources",,,eso-prototype,,
,,,Level 2 and Level 3 requirements,,,,,,
,TXT-9,,Science Processing,,,,,,
MDPS_L1_REQ-1,MDPS_2_REQ-1,L2,"The MDPS shall provide the capability to execute, manage, and monitor data processing workflows in a science processing platform. (Science Processing Platform)","Execute: Includes Forward Stream, Bulk, on-demand, and data simulations executions - based on CWL workflows, WPS-T deployment and undeployment of workflows. 
 
 Manage: execute, retry, 
 
 Monitor: monitor execution(s)",,,eso-prototype,sps,
MDPS_2_REQ-1,MDPS_2_REQ-2,L3,The science processing platform shall provide a Web Processing Service Transactional(WPS-T) interface for workflow management,"WPS-T includes the WPS and the additional transactional standards for the deployment, undeployment of processes.",Test,Integration Test; Test the WPS-T interface and its endpoint by submitting required input parameters and receiving a successful response back.,"eso-prototype, interface",sps,wpst.feature
MDPS_2_REQ-1,MDPS_2_REQ-3,L3,The science processing platform shall meet product generation requirements as defined in the MDPS service level agreement (SLA).,"Scaling, or procurement of hardware necessary to complete processing for a given project (forward stream, bulk reporcessing, on-demand, event driven, etc). All must be defined in the project level SLA. The SLA shall include scaling, timing, availability and failiure targets",Test,System Test,,sps,sla.feature
MDPS_2_REQ-1,MDPS_2_REQ-4,L3,The science processing platform shall allow execution of workflows conforming to the Common Workflow Language (CWL) specification,"The interface specification(s )for science workflows capable of being run in the MMDPS science processing system. This will also necessitate implementations of functionalities (scatter, chaining, etc). Version info TBD",Test,Integration Test,"eso-prototype, interface",sps,cwl.feature
MDPS_2_REQ-1,MDPS_2_REQ-5,L3,The science processing platform shall be able to execute workflows concurrently,The system needs to be able to execute workflows in parallel and take advantage of the available resources,Test,System Test,eso-prototype,sps,concurrent.feature
MDPS_2_REQ-1,MDPS_2_REQ-7,L3,The science processing platform shall provide capabilities to recover from workflow failures,"Failures and how they are to be recovered from are defined by MMDPS Projects. Automate product generation recovery would be ideal, but some cases my require a user intervention. Some examples: transient hardware/network issues, staging/data access issues, etc. Unexpected interface changes.",Test,System Test and UAT,,sps,recovery.feature
MDPS_2_REQ-1,MDPS_2_REQ-8,L3,The science processing platform shall allow project defined rules for executing product workflows.,"Allow projects to define production run rules for a given workflow. These rules could be based on event or trigger (e.g. data availability), timing (every day at midnight, like a cron), or on-demand process (e.g. a web service API). In more advanced scenarios, an external event could initiate processing (e.g. a natural disaster). The workflows are defined ahead of time, but the rules for executing them need to be defined by a user or project (e.g. data availability, cron jobs, etc)
 
 
   
 
 
  The rules a project can leverage include:
 
 
   
 
 
  
 Chaining one workflow completion to the instantiation of another. 
 Data delivery based workflow execution 
 API driven execution (e.g. an explicit command is sent to execute a given workflow)",Test,System Test and UAT,eso-prototype,sps,project_rules.feature
MDPS_2_REQ-1,MDPS_2_REQ-10,L3,"The science processing platform shall provision, manage, and release resources required for workflow processing","The ability to scale up and down processing where applicable to support various workflows and throughput requirements. minimum and maximum on scaling, pre-warming (e.g. proactive scaling), metric based scaling (e.g. CPU, job wait time), scaling down. There are Processing Services environments where this capability may be moot (e.g. on-prem, non-dynamic clusters).",Test,System Test,eso-prototype,sps,resources.feature
MDPS_2_REQ-1,MDPS_2_REQ-11,L3,The science processing platform shall provide workflow and application package execution metrics,"ideally, a single system (e.g. kibana, cloudwatch, etc) to aggregate metrics in a single place for all MMDPS services. The metrics can be filtered, based on the user/role to specific information or not.",Test,System Test,,sps,metrics.feature
MDPS_2_REQ-1,MDPS_2_REQ-12,L3,The science processing platform shall provide workflow error and status messages to end users,"In a distributed system, errors and log messages need to make their way back to the user in one way or another- especially for troubleshooting data flows and processing errors. This does not require or preclude a 'common' mechanism for error log presentation and retention.",Test,System Test and UAT,,sps,information_propagation.feature
MDPS_2_REQ-1,MDPS_2_REQ-13,L3,The science processing platform shall generate provenance for generated products,"The provenance information, or how a product was made, the inputs, and the configurations used shall be stored in the MMDPS.",Test,System Test,,sps,provenance.feature
MDPS_2_REQ-1,MDPS_2_REQ-14,L3,"The science processing platform shall be capable of executing workflows on cloud, on-premise, and HPC compute environments.",The ability to move workloads to dedicated infrastructure (HPC) or cloud is a desired capability of the system for future proofing the implementations.,Test,"Integration Tests, System Test",,sps,hybrid.feature
MDPS_2_REQ-1,MDPS_2_REQ-162,L3,The science processing platform shall provide the capability to prioritize workflow executions.,Prioritize workflow executions (e.g. NRT is higher priority than reprocessing).,Test,System Test,eso,sps,priority.feature
MDPS_2_REQ-1,MDPS_2_REQ-187,L3,The science processing platform shall be capable of one-off or reprocessing campaigns while maintaining forward processing,Forward processing and reprocessing are required of the system.,Test,System Test,"eso, non-functional",sps,non_func_parallel_process.feature
MDPS_2_REQ-1,MDPS_2_REQ-186,L3,The science processing platform shall be capable of reprocessing data at 3x the forward rate.,"Performance Requirements to support the ESO missions, in this case SBG.",Test,System Test,"eso, non-functional",sps,non_func_3x..feature
MDPS_2_REQ-1,MDPS_2_REQ-188,L3,The science processing paltform shall be capable of processing a forward rate of 82 Tb of data in a 24 hour period,SBG (18Tb) + Mass Change (8TB) data processing requirements,Test,System Test,"eso, non-functional",sps,non_func_throughput.feature
MDPS_2_REQ-1,MDPS_2_REQ-189,L3,The science processing platform shall be capable of producing workflow outputs within 24 hours <TBD> of job submission,"SBG, MC, and AOS requirements differ here, but the latency requirement is as fast as '24 hours' from data observation. 
 
 
   
 
 
  We can't commit to data observation schedules, so we use 'job submission' times instead. need more information on the SDS budget from a time perspective.",Test,System Test,"SLA, eso, eso-prototype, non-functional",sps,non_func_latency.feature
MDPS_2_REQ-1,MDPS_2_REQ-193,L3,The science processing platform shall support the usage of ancillary data files up to 1TB in size,"Requirements for processing capabilities from Sips in the cloud requirements,",Test,System Test,"SLA, eso, non-functional",sps,non_func_anc_size.feature
MDPS_2_REQ-1,MDPS_2_REQ-9,L3,The science processing platform shall provide the capability for project customizable data production reporting,"Different projects will have different reporting needs, from latency reports to distribution/usage reports, these need to be customizable from the project perspective. Reports are usually on behalf of Project Users (e.g. Project Processing Services Operators), but could be generalized to MMDPS Staff (uptime for a service area). Other reporting: workflow reporting, product reporting, project reporting including latencies, performance, failures.",Test,System Test,eso-prototype,sps,data_production_reporting.feature
MDPS_2_REQ-1,MDPS_2_REQ-6,L3,The science processing platform shall provide a user interface for workflow monitoring,"Monitor data production via a UI, including throughput, errors, timings, and product reporting.",Test,"System Test, UAT",eso-prototype,sps,ui.feature
MDPS_2_REQ-1,MDPS_2_REQ-174,L3,The science processing platform shall provide aggregate workflow execution metrics,"Aggregate metrics include:
 
 
  
 current jobs being run 
 errors 
 average workflow run times 
 successful runs 
  
 
  these metrics allow for the user to ascertain the health of the processing pipelines and latency for data production audits.
 
 
   
 
 
  Aggregate metrics can be for all workflows or a specific workflow.",Test,System Test,eso,sps,aggregate_metrics.feature
MDPS_2_REQ-1,MDPS_2_REQ-175,L3,The science processing platform shall provide workflow execution metrics by user specified time frames,Allow for aggregation metrics by user defined time (e.g. past 24 hours).,Test,System Test,eso,sps,aggregate_metrics_time.feature
MDPS_2_REQ-1,MDPS_2_REQ-176,L3,The science processing platform shall provide detailed logs for workflow executions,"The ability to view log messages is critical in debugging issues and errors in workflows. Data production can have errors in input data, formats, data availability, transient errors, and more. Often times the logs are the quickest way for an operator to understand the nature of an error and a fix/work around.",Test,"System Test, Submit a CWL workflow that will generate a log with the following information:
 
 
   
 
 
  1. Generate logs that contains Errors and/or Warnings from workflow execution/processing and data production.
 
 
  2. Logs will contain timestamps for when each message gets created.",eso,sps,detailed_logs.feature
MDPS_2_REQ-1,MDPS_2_REQ-177,L3,The science processing platform shall be capable of listing workflow executions,"Monitoring requires a basic investigation of the workflow executions, status, and metadata. Listing these executions for programmatic exploration or UI exploration.
 
 
   
 
 
  While the WPS-T requirement also provides for listing workflows, this would not be limited to listing by OGC WPS ""Processes"", and could span multiple processes (i.e. deployed product generation workflows).",Inspection,Visually examine a list of workflow execution status on the Dashboard (Programmatic exploration or UI exploration).,"eso, eso-prototype",sps,execution_listings.feature
MDPS_2_REQ-1,MDPS_2_REQ-178,L3,The science processing platform shall be capable of filtering workflow execution metrics by workflow metadata,"Filtering of the workflow by workflow metadata: submisison time, status, etc.",Test,"System Test, Demonstrate the filtering mechanism via workflow metadata - submission time, status, etc.",eso,sps,execution_listing_filter.feature
MDPS_2_REQ-1,MDPS_2_REQ-179,L3,The science processing platform shall be capable of notifying users of workflow execution errors,Operators can be alerted to workflow errors as they occur. The mechanisms for 'alerts' is implementation specific.,Test,"System Test, UAT, Submit a CWL Workflow with incorrect inputs (incorrect filename or missing files from database). Ensure User gets notified of the Workflow error after the execution fails.",eso,sps,error_notification.feature
MDPS_2_REQ-1,MDPS_2_REQ-180,L3,The science processing platform shall be capable of listing recent workflow execution notifications,"workflow execution notifications can include notices of success, failure, latency triggers, etc.",Test,"System Test, Visually inspect that the dashboard and logs contain various notifications (success, failures, latency triggers) from the workflow execution.",eso,sps,error_notification_listing.feature
MDPS_2_REQ-1,MDPS_2_REQ-167,L3,The science processing platform shall provide the capability to execute workflows based on data availability,Ability to start a workflow when data are made available is a key ability.,Test,"System Test, Integration Test, 1. Submit the CWL Workflow via Jupyter Notebook for processing. Ensure that the workflow completes and generates a product.
 
 
  2. Submit the CWL Workflow via Python Script (API) for processing. Ensure that the workflow completes and generates a product.",eso,sps,availability.feature
MDPS_L1_REQ-1,MDPS_2_REQ-15,L2,The MDPS shall provide the capability to author and update data processing workflows.. (Workflow Authoring Tool),"Workflows are comprised of Algorithms (application packages) and other workflow steps that are used to encapsulate complex processing. This tool will allow projects to define project specfic workflows including the inputs, steps, and outputs. Workflows can also define scattering/mapping, reduction, and the triggering of other workflows.",,,,workflow_authoring_tool,
MDPS_2_REQ-15,MDPS_2_REQ-16,L3,The workflow authoring tool will provide a UI to users for the authoring of workflows,"Workflow languages can be complex, a UI for a visual editor or workflows is ideal for seeing the flow. Not the will in the requirement text. This is a future requirement to enable the _simple_ development of workflows and adoption of the CWL system.",Test,"System Test, UAT",,workflow_authoring_tool,
MDPS_2_REQ-15,MDPS_2_REQ-17,L3,The workflow authoring tool shall provide workflow syntax validation,The tool needs to let a user know if they are creating a valid or invalid workflow based on workflow specifications and application package requirements,Test,System Test,,workflow_authoring_tool,
MDPS_2_REQ-15,MDPS_2_REQ-18,L3,The workflow authoring tool shall provide the capability to publish workflows to a workflow catalog,"Given a workflow in the tooling, it can be published for use in the MMDPS science processing system",Test,System Test,,workflow_authoring_tool,
MDPS_2_REQ-15,MDPS_2_REQ-19,L3,The workflow authoring tool shall allow discovery of available application packages in the MDPS application catalog for inclusion in authored workflows,"Being able to discover and ""insert"" an existing application package (CWL workflow) in the application catalog for inclusion in workflows",Test,System Test,,workflow_authoring_tool,
MDPS_2_REQ-15,MDPS_2_REQ-20,L3,The workflow authoring tool shall allow discovery of available processing workflows in the MDPS workflow catalog for duplicating and updating,"Allow for the 'copy' or 'save as' so that someone can take an existing workflow and repurpose it for their own use case. using the published workflow as a ""starting point"".",Test,System Test,,workflow_authoring_tool,
MDPS_2_REQ-15,MDPS_2_REQ-183,L3,The workflow authoring tools shall provide example template workflows,Provide example workflows for reference and user education. these can also be copied and modified to provided a basis of getting started in workflow authoring.,Test,System Test,eso,workflow_authoring_tool,
MDPS_L1_REQ-1,MDPS_2_REQ-21,L2,"The MDPS shall provide a shared workflow catalog for the registration, search and access to processing workflows (Workflow Catalog)",Need a shared service for the cataloging of workflows (consisting of one or more applications packages and tasks) to enable the handoff between different venues.,,,eso-prototype,workflow_catalog,managed_service.feature
MDPS_2_REQ-21,MDPS_2_REQ-22,L3,The workflow catalog shall allow the publishing of data processing workflows,Needs to be able to take in new or versioned workflows and make them available in the system.,Test,System Test,eso-prototype,workflow_catalog,publication.feature
MDPS_2_REQ-21,MDPS_2_REQ-23,L3,The workflow catalog shall allow access to workflows,"be able to 'download' the artifact representing the executable workflow, includes the sharing of it with other users.",Test,System Test,eso-prototype,workflow_catalog,access.feature
MDPS_2_REQ-21,MDPS_2_REQ-24,L3,The workflow catalog shall allow deletion of workflows,Workflows can be deleted from the system; but references to the workflow should persist for provenance purposes- this essentially acts as a deprecation or 'do not user' flag,Test,System Test,,workflow_catalog,workflow_deletion.feature
MDPS_2_REQ-21,MDPS_2_REQ-25,L3,The workflow catalog shall allow discovery of workflows,"e.g. a browsable/filterable way of finding workflows, can't expect users to know of all the published workflows through some other mechanism.",Test,System Test,eso-prototype,workflow_catalog,discovery.feature
MDPS_2_REQ-21,MDPS_2_REQ-26,L3,The workflow catalog shall maintain a record of deleted workflows,Deleted workflows are 'marked as deleted' and not deleted from the system so that provenance can continue,Test,System Test,,workflow_catalog,workflow_deletion_record.feature
MDPS_2_REQ-21,MDPS_2_REQ-27,L3,The MDPS shall provide the capability to publish multiple versions of a workflow,"workflows can change over time, so allow for versioned workflows. Previous workflows should be discoverable especially from provenance standpoints.",Test,System Test,eso-prototype,workflow_catalog,workflow_versions.feature
MDPS_2_REQ-21,MDPS_2_REQ-28,L3,The workflow catalog shall provide the capability to restrict access to workflows,"Allow projects to decide who can access a workflow, useful for development purposes.",Test,System Test,,workflow_catalog,access_restrictions.feature
MDPS_2_REQ-21,MDPS_2_REQ-184,L3,The workflow catalog shall provide error messages upon invalid requests,"Errors can occur when an ill-formatted workflow are supplied, missing parameters, or permissions baed issues arise.",Test,System Test,eso,workflow_catalog,errors.feature
MDPS_2_REQ-21,MDPS_2_REQ-216,L3,The workflow catalog shall be available 99.9% of the time or greater,"Due to dependencies on the component, the availability requirement for the shared service is greater than the other specified (99%) requirements.",Test,"System test and monitoring availability over the course of a rolling day, week, month","eso, non-functional",workflow_catalog,uptime.feature
,TXT-10,,Generic Data Services,,,,,,
MDPS_L1_REQ-1,MDPS_2_REQ-29,L2,The MDPS shall provide a shared data catalog for cataloging and search of MDPS data products based on product metadata. (Data Catalog),"The data products (e.g. files) are stored in project/venue specific locations, but the metadata for _finding_ those is stored in shared, multi-tenant catalog. Catalog products include generated products and products needed to generate science data products (ancillary, auxiliary, lower level products) where applicable. Search includes name, type and other searchable options. It is not the responsiblity of the data catalog to generate metadata for the products, it must be told. The catalog will also accommodate custom metadata provided by the project/venue either dynamically or through pre-registration of those fields.",,,eso-prototype,data_catalog,managed_service.feature
MDPS_2_REQ-29,MDPS_2_REQ-30,L3,The data catalog shall allow search on cataloged products through a Data Access and Processing API (DAPA) interface,DAPA as the interface for searching and (some) data based processing requests,Test,System Test,"eso-prototype, interface",data_catalog,dapa.feature
MDPS_2_REQ-29,MDPS_2_REQ-31,L3,The data catalog shall allow search for data products by parent collections,"a collection is a container for all the products within it. A product (consisting of one or more files such as data, metadata, checksums, browse imagery, etc) is usually a spatial or temporal subset of the entire collection. That is, 12 monthly products would make collection with one year of coverage.",Test,System Test,eso-prototype,data_catalog,parent_collections.feature
MDPS_2_REQ-29,MDPS_2_REQ-32,L3,The data catalog shall allow notifications of newly cataloged data products,"To enable sharing or value added processing, when data are available or registered in the system, a user should be able to be notified of its availability. This might be useful in Processing Services forward processing, on-demand processing, etc, where higher level data products are processed from lower level data products. non-standard workflows might also be run through the analysis service area. For example, if a new product comes in, an application users might want to automatically kick off processing to incorporate that data into a weather prediction, etc.
 
 
   
 
 
  Formerly ""subscription"" now ""notification""",Test,System Test,,data_catalog,notifications.feature
MDPS_2_REQ-29,MDPS_2_REQ-33,L3,The data catalog shall return search results in STAC (SpatioTemporal Asset Catalogs) format,STAC as an interchange format for collection and product search results,Test,System Test,"eso-prototype, interface",data_catalog,stac.feature
MDPS_2_REQ-29,MDPS_2_REQ-34,L3,The data catalog shall allow search for data products on spatial and temporal metadata.,Space and time searchability is mandatory,Test,System Test,,data_catalog,spatiotemporal_search.feature
MDPS_2_REQ-29,MDPS_2_REQ-35,L3,The data catalog shall provide the capability to discover collections,"Collection discovery includes listing all collections, filtering collections based on specific criteria (e.g. processing level, spatial and temporal coverage)",Test,System Test,eso-prototype,data_catalog,collection_discovery.feature
MDPS_2_REQ-29,MDPS_2_REQ-36,L3,The data catalog shall catalog products with required metadata as specified in <DATA-CATALOG-TBD>,"file creation, file name, tenant, venue, provenance, type (product, aux/anc), TBD",Test,System Test,eso-prototype,data_catalog,ingest_with_required_metadata.feature
MDPS_2_REQ-29,MDPS_2_REQ-37,L3,The data catalog shall provide the capability to search data products on project provided metadata,"Aside from required metadata (file creation, file name, tenant, venue, provenance, type (product, aux/anc), projects should be able to provide their own product based metadata. This might include things like a processing identifier (forward, reprocessing), cloudcover, and more.",Test,System Test,,data_catalog,project_define_metadata.feature
MDPS_2_REQ-29,MDPS_2_REQ-38,L3,The data catalog shall require provenance information for all cataloged records.,"To provide provenance in the system, cataloged items require a lineage of where the product came from, and optionally how it was created. For data from a GDS it would be the record of when this data was delivered. For data from a DAAC&lt; it would include a link to the original data and time of retrievela. For generated data, it would include th inputs, processing workflows, and processing environment provenance.",Test,System Test,,data_catalog,provenance.feature
MDPS_2_REQ-29,MDPS_2_REQ-39,L3,The data catalog shall provide the capability to restrict operations to authorized users.,"Catalog needs some protections for ""restricting"" actions on the data catalog. For example, restricting search results to data based on some mechanisms. This could be to enable ""open"" data, or to restrict access within a project to only select team members. 
 
 
   
 
 
  This will also include the ability to _create_ collections, delete collections, and add data to a collection (which you may not own).",Test,System Test,eso-prototype,data_catalog,authorized_users.feature
MDPS_2_REQ-29,MDPS_2_REQ-214,L3,The data catalog shall be available 99.9% of the time or greater,"Due to dependencies on the component, the availability requirement for the shared service is greater than the other specified (99%) requirements.",Test,"System test and monitoring availability over the course of a rolling day, week, month.","eso, non-functional",data_catalog,uptime.feature
MDPS_L1_REQ-1,MDPS_2_REQ-40,L2,The MDPS shall allow the capability to deliver data products to NASA approved archives (archive system),"The ability of an SDS to send or notify an archive of data ready to be stored for long term preservation is a key requirement of any SDS. The SDS may contain a life of mission storage, but is not the long term location for data archival.",,,,archive_system,
MDPS_2_REQ-40,MDPS_2_REQ-41,L3,The archive system shall provide a common mechanism for delivering data to DAACs,DAACs are one of the archive systems the MDPS SDS must interact with.,Test,"System Test, Integration Test",,archive_system,daac_interface.feature
MDPS_2_REQ-40,MDPS_2_REQ-42,L3,The archive system shall provide a common mechanism for delivering data to PDS nodes,PDS nodes are one of the archive systems the MDPS SDS must interact with.,Test,"System Test, Integration Test",,archive_system,pds_interface.feature
MDPS_2_REQ-40,MDPS_2_REQ-43,L3,The archive system shall monitor the archive process for success and errors,In the event of synchronous or asynchronous scenarios the system needs to be able to respond to success and failures,Test,"System Test, Integration Test",,archive_system,daac_interface.feature
MDPS_2_REQ-40,MDPS_2_REQ-44,L3,The archive system shall provide reporting on product archive processes,"The archive system shall provide information/reporting on success and failures, latencies, and if a product is archived or not",Test,"System Test, Integration Test",,archive_system,reporting.feature
MDPS_2_REQ-40,MDPS_2_REQ-190,L3,The archive service shall be capable of making standard products available to the DAACs within 5 minutes after the product is produced.,Requirements from the sips in the cloud mission,Test,System Test,"SLA, eso, non-functional",archive_system,latency.feature
MDPS_2_REQ-40,MDPS_2_REQ-218,L3,The archive service shall support asynchronous archive process requests,"Due to it's role in the processing workflow, the archive services cannot be a blocking step. This requires the ability to submit requests to the service regardless of the status of the archive service, and queue and process steps after recovering from a downtime.",Test,system tests,eso,archive_system,async.feature
MDPS_L1_REQ-1,MDPS_2_REQ-45,L2,The MDPS shall provide the capability to retrieve data from project approved sources.,"Retrieve for the purposes of ingest (e.g. copying into the MDPS data system) or processing. Telemetry productss and low-level data that will be processed into higher level data products that come from NASA approved ground networks, international partners, and commercial providers such as ground stations, mission and science operation centers, etc. This can also include Archives for on-demand style processing or systems like OPERA and CalCIS that take existing archived earthdata and transform it into value added products.",,"System Test, Integration Test",eso-prototype,approved_data_sources,
MDPS_2_REQ-45,MDPS_2_REQ-46,L3,The MDPS shall provide the capability for users to access resources in NASA approved archives,"Data for algorithm development, testing and validation may reside in PDS or DAAC like archives, access here would entail using data directly from the archive, and not 'duplicating' it within the MDPS.",Test,"System Test, Integration Test",eso-prototype,approved_data_sources,access_nasa_archives.feature
MDPS_2_REQ-45,MDPS_2_REQ-47,L3,The MDPS shall provide the capability for users to search resources in NASA approved archives,"Data for algorithm development, testing and validation may reside in PDS or DAAC like archives, search would allow finding specific products for the purpose of processing.",Test,"System Test, Integration Test",eso-prototype,approved_data_sources,search_nasa_archives.feature
MDPS_2_REQ-45,MDPS_2_REQ-48,L3,The MDPS shall provide the capability for users to stage and catalog data from project approved resources within the MDPS,"Data from an approved system (e.g. ground data system) needs to be ingested and cataloged. Mechanisms can include polling, pushing and 'to-the-doorstep'' (data are pushed directly to a known MDPS store for future usage)",Test,"System Test, Integration Test",,approved_data_sources,stage_and_catalog_resources.feature
MDPS_L1_REQ-1,MDPS_2_REQ-49,L2,"The MDPS shall provide mission storage, access and management functionalities for MDPS data products (Mission Store)","The ability to store and manage data products as part of the SDS is required to ensure mission safekeeping. Agreements with project may limit the amount of data required to be stored at any given time.
 
 
   
 
 
  The mission storage referenced in this requirement can be temporary or up to the life of the mission, at which time all required data must be transferred to an archive.",,,eso-prototype,mission_store,
MDPS_2_REQ-49,MDPS_2_REQ-194,L3,The mission store shall meet storage requirements as defined in the MDPS service level agreement (SLA).,"Includes rolling storage, versioning, IA and cold storage technologies",Test,System Test,"SLA, non-functional",mission_store,sla.feature
MDPS_2_REQ-49,MDPS_2_REQ-50,L3,The mission store shall provide access to data products using the HTTPS protocol,Allow for https based access to data products within the system due to its ubiquitous nature.,Test,System Test,"eso-prototype, interface",mission_store,https.feature
MDPS_2_REQ-49,MDPS_2_REQ-51,L3,The mission store shall allow project specific versioning of data products,"versioning by product name, product collection, or by infrastructure versioning (e.g. bucket level versioning in AWS). Because different projects will version files differently, we cannot prescribe _how_ this is done. Many teams will use some identifier in the filename themselves to create uniqueness- create date, CRID, or version number.",Test,System Test,eso-prototype,mission_store,versioning.feature
MDPS_2_REQ-49,MDPS_2_REQ-52,L3,The mission store shall store data products in the MDPS as documented in the MDPS service level agreement (SLA).,"Details on availability, durability, robustness of data storage solutions are maintained in an evolving Service Level Agreement (SLA)",Test,System Test,,mission_store,sla_storage.feature
MDPS_2_REQ-49,MDPS_2_REQ-53,L3,The mission store shall provide the capability to remove data after an amount of time as specified in a project service level agreement.,Data my be automatically deleted after X days for development data.,Test,System Test,,mission_store,rolloff.feature
MDPS_2_REQ-49,MDPS_2_REQ-54,L3,The mission store shall provide the capability to recover data as specified in a project service level agreement.,"Project data may need to be recoverable from accidental deletions, overwrites, etc",Test,System Test,,mission_store,recovery.feature
MDPS_2_REQ-49,MDPS_2_REQ-55,L3,The mission store shall allow whole file download of data products,"Whole file download of data is one access method required, this is equivalent fo download the entire file via https. Other (non-required) options could include subset or aggregation baed access (OPeNDAP and THREDDS, for example).",Test,System Test,eso-prototype,mission_store,whole_file_download.feature
MDPS_2_REQ-49,MDPS_2_REQ-56,L3,The mission store shall provide the capability to store ancillary and auxiliary products.,"Ancillary and Auxiliary products are used int eh creation of data products. the avenue for storing them may not be through an automated system, or may happen outside of the MMDPS itself.",Test,System Test,eso-prototype,mission_store,anc_and_aux.feature
MDPS_2_REQ-49,MDPS_2_REQ-166,L3,The mission store shall be capable of notifying consumers of new data.,"workflows might want to be triggered when data becomes available. Or some other process might need to be run when specific data are available (e.g. new models for job inputs).
 
 
   
 
 
  Consumers can be human or machine. Should give basic information of the file being added (bucket, key, etc).",Test,"System Test, Integration Test",eso,mission_store,notification.feature
MDPS_2_REQ-49,MDPS_2_REQ-168,L3,The mission store shall store interface responses from NASA approved archives.,,Test,"System Test, Integration Test",,mission_store,archive_message.feature
MDPS_2_REQ-49,MDPS_2_REQ-191,L3,The mission store shall be capable of a sustained storage rate of <TBD>20TB of data over 24 hours,"Data ingest rates from ESO Missions:
 
 
  mission downlink + outputs = total
 
 
  MC 8TB + 50GB = ~9TB 
 
 
  SBG = 18Tb + X = ~?2.2TB 
 
 
  AOS = 690GB + Y = ~1TB
 
 
   
 
 
  + 1.5X burst rate = ~20TB",Test,System Test,"SLA, eso, eso-prototype, non-functional",mission_store,storage_rate.feature
MDPS_2_REQ-49,MDPS_2_REQ-192,L3,The mission store shall be capable of storing files up to <TBD> 1TB,"""Hundreds of GB"" requirement from Sips in the Cloud",Test,System Test,"SLA, eso, eso-prototype, non-functional",mission_store,file_size.feature
,TXT-11,,Analysis Services,,,,,,
MDPS_L1_REQ-2,MDPS_2_REQ-57,L2,The MDPS shall provide with an interactive development environment (IDE).,"Allow the MDPS to provide a COTS based interactive developer environment (e.g. Jupyter, eclipse che) for the purpose of creating algorithms, validating products and performing analysis. this is not intended to be a custom IDE, but to facillitate the deployment, setup, and permissions of COTS based IDEs.",,,eso-prototype,ide,
MDPS_2_REQ-57,MDPS_2_REQ-58,L3,The IDE shall interface with git-based software version control systems.,"At least JPL github and public github repositories. Development environments include algorithm, analysis, and visualization environments.",Test,System Test,eso-prototype,ide,git.feature
MDPS_2_REQ-57,MDPS_2_REQ-59,L3,The IDE shall provide development environments access to MDPS data,"Access to previously generated data within the MDPS, or other data stored/archived within MDPS (ancillary, auxiliary data). This would also include results/data from previously run tests using the algorithm development environment. Development environments include algorithm environments and analysis environments.",Test,"System Test, Integration Test",eso-prototype,ide,data_access.feature
MDPS_2_REQ-57,MDPS_2_REQ-60,L3,The IDE shall allow testing of algorithms within the user's environment,"Here, a user maintains control over all inputs and outputs local to their environment. This algorithm does not need to match any type of spec and has limited impact on the MMDPS as a whole. This requirement is in contrast to testing within a production like workflow, such as the Processing Services, where interfaces, packaging, and rules are more rigidly defined but are useful for a more mature algorithm.",Test,"System Test, UAT",eso-prototype,ide,testing.feature
MDPS_2_REQ-57,MDPS_2_REQ-61,L3,The IDE shall allow users to upload data to the IDE environment,"Users, especially in early portions of testing, will want to work with their own data in their own, controlled environment before enabling MMDPS libraries, interfaces, access to data stores, etc.
 
 
 
 
 
 
 
 
 
 
 
 Development environments include algorithm, analysis, and visualization environments.",Test,System Test,eso-prototype,ide,upload.feature
MDPS_2_REQ-57,MDPS_2_REQ-62,L3,The IDE shall be web-based,Supporting development through Jupyter notebooks or similar helps lower the learning curve involved in algorithm development.,Test,System Test,eso-prototype,ide,ui.feature
MDPS_2_REQ-57,MDPS_2_REQ-63,L3,The IDE shall allow sharing of code and data between IDE users,Allow the collaboration of algorithms by way fo code and data sharing.,Test,"System Test, UAT",,ide,data_sharing.feature
MDPS_L1_REQ-2,MDPS_2_REQ-64,L2,"The MDPS shall provide a shared application catalog for the registration, search and access to application packages (Application Catalog)","A place to view/extend existing application packages. Also used to integrate developed algorithms into the product generation workflows and lifecycle between venues (e.g. dev to test). Artifacts can include binaries, metadata, and other executable configurations",,,eso-prototype,application_catalog,managed_service.feature
MDPS_2_REQ-64,MDPS_2_REQ-65,L3,The application catalog shall allow discovery of application packages,"The idea here is a PGE catalog / Marketplace for re-use or to facilitate the ability to test algorithms in the same manner as a production system. Discovery of application packages by name, submitting users, etc.",Test,System Test,eso-prototype,application_catalog,applicaiton_discovery.feature
MDPS_2_REQ-64,MDPS_2_REQ-66,L3,The application catalog shall provide the capability to publish multiple versions of an application package,Algorithms may have one or more versions as updates are made. These should be tracked for historical comparison and provenance.,Test,System Test,eso-prototype,application_catalog,application_publicaiton.feature
MDPS_2_REQ-64,MDPS_2_REQ-67,L3,The application catalog shall allow access to application packages from the centralized catalog,The catalog points at resources required to run the cataloged application package.,Test,System Test,eso-prototype,application_catalog,application_access.feature
MDPS_2_REQ-64,MDPS_2_REQ-68,L3,The application catalog shall allow deletion of application packages from a centralized algorithm catalog,"May need to remove the algorithm from the store for a variety of reasons. this shouldn't be part of the normal lifecycle, since other projects, users, workflows might be using or have used this algorithm.In the event of a published application being deleted, other requirements defne the need to keep a record of the delted entry.",Test,System Test,,application_catalog,application_deletion.feature
MDPS_2_REQ-64,MDPS_2_REQ-69,L3,The application catalog shall maintain a record of deleted application packages,"even if deleted, a record for this must be maintained or provenance information. Deleted applciation packages should not be discoverable through default searches.",Test,System Test,,application_catalog,application_deletion_record.feature
MDPS_2_REQ-64,MDPS_2_REQ-70,L3,The application catalog shall provide the capability to publish application packages conforming to the published OGC Best Practice for Earth Observation Application Package,"the basic operation of registering an algorithm package in the repository for use in a workflow. The application package specification can be found at 
 
 
  http://www.opengis.net/doc/BP/eoap/1.0",Test,System Test,"eso-prototype, interface",application_catalog,OGC_validations.feature
MDPS_2_REQ-64,MDPS_2_REQ-71,L3,The application catalog shall provide the capability to restrict access to application packages,Projects may want to restrict access to application packages in development.,Test,System Test,,application_catalog,application_access_restrictions.feature
MDPS_2_REQ-64,MDPS_2_REQ-72,L3,The application catalog shall support language agnostic application packages,"So long as the application is packaged correctly, the underlying implementation language (java, python) etc should not matter. There may be impacts on the required run-times for executing an application package (e.g. IDL), but from an application package perspective, this is not prescribed.",Test,System Test,eso-prototype,application_catalog,application_lang_agnostic.feature
MDPS_2_REQ-64,MDPS_2_REQ-215,L3,The application catalog shall be available 99.9% of the time or greater,"Due to dependencies on the component, the availability requirement for the shared service is greater than the other specified (99%) requirements.",Test,"System test and monitoring availability over the course of a rolling day, week, month","eso, non-functional",application_catalog,uptime.feature
MDPS_2_REQ-64,MDPS_2_REQ-221,L3,The application catalog shall store execution metrics for each application package in the catalog,"User can determine the cost of executing an application package. Execution metrics can consist of runtime, CPU usage, and memory usage.",Test,,,application_catalog,application_execution_metrics.catalog
MDPS_L1_REQ-2,MDPS_2_REQ-73,L2,The MDPS shall provide the capability for IDE customization,The IDE shall be customizable for the project's and user's needs.,,,eso-prototype,ide,
MDPS_2_REQ-73,MDPS_2_REQ-74,L3,IDE customization shall include IDE compute resources,"Allow for customizing the amount of resources an IDE environment has, or what a user has access to (CPU, RAM).
 
 
   
 
 
  This means that when the IDE is first deployed, the total amount of CPU/RAM on an 'instance' can be customized. The users can also specify (or request) how much ram/cpu is given to their specific IDE during run time. This might be a list of options (e.g. 2 CPU, 8 CPU, 16 CPU) and must be set up prior by the project.",Test,System Test,eso-prototype,ide,compute.feature
MDPS_2_REQ-73,MDPS_2_REQ-75,L3,IDE customization shall include IDE storage resources,"Alow for customizing the storage available to an environment (e.g. SSD Storage, 20TB of storage)",Test,System Test,eso-prototype,ide,storage.feature
MDPS_2_REQ-73,MDPS_2_REQ-76,L3,IDE customization shall include the inclusion of project defined libraries and resources to IDEs,"allow for things like GDAL, file readers, custom software to be installed",Test,System Test,,ide,libraries.feature
MDPS_L1_REQ-2,MDPS_2_REQ-77,L2,The MDPS shall provide the capability to package developed algorithms as application packages for execution in a science data processing platform. (Application Package Generation System - APGS),A system for taking code from an IDE and package and publish it in the catalog for future executions,,,eso-prototype,apgs,managed_service.feature
MDPS_2_REQ-77,MDPS_2_REQ-78,L3,The APGS shall preserve source code used to construct an application package,"The code used for the algorithm must be 'configuration managed' for historical reference and re-building. The _act_ of rebuilding it (for all time) is out of scope for MDPS, but having the underlying record is required.",Test,System Test,,apgs,preserve_source.feature
MDPS_2_REQ-77,MDPS_2_REQ-79,L3,The APGS shall generate algorithm packages as defined in http://www.opengis.net/doc/BP/eoap/1.0,"Algorithm packages' can be defined offline/locally or through a managed based system. Once built (preferably automatically) the asset is cataloged and now runable from a MMDPS Processing Services workflow, and is stored in the Algorithm Catalog",Test,System Test,"eso-prototype, interface",apgs,app_pacakges.feature
MDPS_2_REQ-77,MDPS_2_REQ-80,L3,The APGS shall store application package artifacts required for execution,"Artifacts from the build,e.g. CWL, Docker containers, etc shall be stored for access",Test,System Test,eso-prototype,apgs,packaging.feature
MDPS_2_REQ-77,MDPS_2_REQ-81,L3,The APGS shall publish application packages to the application catalog,Publish the built application packages to the application catalog.,Test,System Test,eso-prototype,apgs,packaging.feature
MDPS_2_REQ-77,MDPS_2_REQ-82,L3,The APGS shall implement measures to prevent malicious MMDPS platform code and data from being run in production like venues.,"MMDPS platform code, or the multi-tenant services need oversight of code quality, vulnerability scans, etc. The goal of this is to prevent rogue code from being added to the MMDPS.",Test,System Test,,apgs,malicious_code.feature
MDPS_2_REQ-77,MDPS_2_REQ-163,L3,The APGS shall provide a mechanism to validate APGS inputs prior to build,A validation mechanism for users to run against artifacts to know if it is compliant or not. This can be run in the IDEA against local files or can be run against a SCM link,Test,"System Test, UAT",eso,apgs,validate_inputs.feature
MDPS_2_REQ-77,MDPS_2_REQ-164,L3,The APGS shall generate application packages upon user request.,A way of calling the APGS is required for integration into user processes/workflows.,Test,System Test,"eso, eso-prototype",apgs,packaging.feature
MDPS_2_REQ-77,MDPS_2_REQ-165,L3,The APGS shall provide status of application generation processes,Users need to determine if builds were successful. This status can be automated (email notifications) or passive (request based).,Test,System Test,eso,apgs,packaging.feature
MDPS_2_REQ-77,MDPS_2_REQ-222,L3,Application packages generated by the APGS shall specify memory resource requirements,Need to know or describe the memory resources required to run an application package in the MDPS system,Test,system test,eso,apgs,memory_requirements.feature
MDPS_2_REQ-77,MDPS_2_REQ-223,L3,Application packages generated by the APGS shall specify CPU resource requirements,"Application packages need to define number of cores, possibly CPU limits for efficient processing.",Test,System Test,eso,apgs,cpu_requirements.feature
MDPS_2_REQ-77,MDPS_2_REQ-224,L3,Application packages generated by the APGS shall specify storage resource requirements,Many algorithms have voluminous data requirements. These must be specified for efficient execution of algorithms,Test,System Test,eso,apgs,storage_requirements.feature
MDPS_L1_REQ-2,MDPS_2_REQ-83,L2,The MDPS shall allow project users to transform and analyze selected MDPS data products (Transformation and Analysis),Allow for basic transformations on project specified product types,,,,analysis,
MDPS_2_REQ-83,MDPS_2_REQ-84,L3,The transformation and analysis system shall reproject/regrid project specified products into user requested reference frames,Allow for reprojection/regridding of suitable data products,Test,System Test,,analysis,regrid.feature
MDPS_2_REQ-83,MDPS_2_REQ-85,L3,The transformation and analysis system shall implement a Data Analysis And Processing API (DAPA) as specified in <DAPA-TBD>,DAPA allows for the request of data in various formats and includes data reduction analytics by default. Based on DGSS implementation https://docs.ogc.org/per/20-025r1.html#_dapa_design_1_for_dggs,Test,System Test,interface,analysis,dapa.feature
MDPS_2_REQ-83,MDPS_2_REQ-86,L3,The transformation and analysis system shall provide dynamic mapping of collections to DAPA implementations,"Projects choose if a product has a DAPA implementation, and so this needs to be dynamically set by the product provider- e.g. a time series capability might exist for product 1 but not product 2",Test,System Test,,analysis,mapping.feature
MDPS_2_REQ-83,MDPS_2_REQ-87,L3,The transformation and analysis system shall provide timeseries calculations on transformation requests,"Return time series from an xform request - domain can be a pixel, area or grid cell",Test,"System Test, UAT",,analysis,time_series.feature
MDPS_2_REQ-83,MDPS_2_REQ-88,L3,The transformation and analysis system shall provide averaging calculations on transformation requests,"Return area average from an xform request. Request can specify area, pixel, or grid cell.",Test,"System Test, UAT",,analysis,averaging.feature
MDPS_2_REQ-83,MDPS_2_REQ-213,L3,The transformation and analysis system shall provide extrema calculations on transformation requests,"Server side functions to return extrema of a given request (e.g. min/max values of a point, area, or polygon request).",Test,System Test,"eso, functional",analysis,extrema.feature
MDPS_2_REQ-83,MDPS_2_REQ-89,L3,The transformation and analysis system shall subset project specified products along user requested space/time bounds,Allow for subsets of data products,Test,"System Test, UAT",,analysis,subset.feature
MDPS_2_REQ-83,MDPS_2_REQ-90,L3,The transformation and analysis system shall provide tooling to generate analysis optimized products,Tooling to generate analysis ready/optimize formats from conventional products- e.g. convert a set of netcdf to zarr archives,Test,System Test,,analysis,aods.feature
MDPS_2_REQ-83,MDPS_2_REQ-91,L3,The transformation and analysis system shall generate provenance records for transformations and analysis requests,"A transformation or analysis request of a data product should create records of what inputs and transformations occured. These records can be ephemeral, but if the resulting products are added back into the MMDPS, the record of where they are from shall be required.",Test,System Test,,analysis,provenance.feature
MDPS_2_REQ-83,MDPS_2_REQ-92,L3,The transformation and analysis system shall provide time-averaged maps on transformation requests,The ability to create a time averaged map is very hand for the analysis and validation of products especially at higher levels.,Test,"System Test, UAT",,analysis,time_average_maps.feature
MDPS_2_REQ-83,MDPS_2_REQ-212,L3,The transformation and analysis system shall provide a way to limit operations to spatial bounds,"Users are generally only concerned with a region of interest, not ""all data"". Ways of specifying spatial bounds will be defined at lower levels (e.g. how), but we will offer point, boundingbox and polygon (via geojson, HUC ID, or other mechanism).",Test,System Test,"eso, functional",analysis,spatial_limits.feature
,TXT-12,,Infrastructure - MDPS Multi-Project Support,,,,,,
MDPS_L1_REQ-3,MDPS_2_REQ-93,L2,The MDPS shall logically isolate projects (Project Isolation),Projects shall be independent entities within the MDPS. Access to the resources of one project does not allow access to non-project resources unless by way of the MDPS shared services specified in this document.,,,eso-prototype,project_isolation,
MDPS_2_REQ-93,MDPS_2_REQ-94,L3,Project Isolation shall provide data search and access across all project venues,Projects can search and access data from other venues (e.g. dev and test can access (read) operational data) but not modify them. The project can define further restrictions on the sharing of data across venues if they'd like.,Test,"System Test, Integration Test",eso-prototype,project_isolation,search.feature
MDPS_2_REQ-93,MDPS_2_REQ-95,L3,Project isolation shall include default user groups for A&A across all project venues,"In order to make the MMDPS permissions work, default 'Project' and 'venue' groups will be created. This allows for project based permissions and venue based permissions.",Test,"System Test, Integration Test",eso-prototype,project_isolation,auth.feature
MDPS_L1_REQ-3,MDPS_2_REQ-96,L2,The MDPS shall provide one or more venues for project specific needs (project venues),"Venues isolate cost and computational impacts across project venues, as well as allow for data sharing and support for algorithm and project lifecycle development. project specific needs could be separation of forward and bulk reprocessing, dev, test and ops environments for lifecycle development and maintenance, etc.",,,eso-prototype,project_venues,
MDPS_2_REQ-96,MDPS_2_REQ-97,L3,Project Venues shall optionally be provided one or more science processing platforms,"A venue can have 0, one or multiple processing systems.",Test,System Test,eso-prototype,project_venues,process.feature
MDPS_2_REQ-96,MDPS_2_REQ-98,L3,Project Venues shall optionally be provided one or more interactive development environments,"A venue can have 0, one or multiple IDEs",Test,System Test,eso-prototype,project_venues,ide.feature
MDPS_2_REQ-96,MDPS_2_REQ-99,L3,Project Venues shall optionally be provided one or more transformation and analysis systems,Venues get their own transformation and analysis system (e.g. SDAP deployed to a specific venue),Test,System Test,,project_venues,analysis.feature
MDPS_2_REQ-96,MDPS_2_REQ-100,L3,Project Venues shall be provided one mission storage system,"Venues get their own data stroage systems (that can consist of multiple directories, buckets, etc).",Test,System Test,eso-prototype,project_venues,storage.feature
MDPS_2_REQ-96,MDPS_2_REQ-101,L3,Project Venues shall allow for the deployment of managed services,"Once a venue account is created, the deployment of venue services can be triggered by venue administrators.",Test,System Test,"eso, eso-prototype",project_venues,managed.feature
MDPS_2_REQ-96,MDPS_2_REQ-160,L3,Project Venue resources shall be requested through a centralized endpoint (Web Gateway),Driving requirement to make the designs work for abstraction of managed services. Access to managed services goes through a central web gateway to enable A&amp;A controls and provide upgrade paths with minimal impact to the user.,Test,System Test,"eso, eso-prototype, interface",project_venues,web_gateway.feature
MDPS_2_REQ-96,MDPS_2_REQ-217,L3,The Web Gateway shall be available 99.9% of the time or greater,"Due to dependencies on the component, the availability requirement for the shared service is greater than the other specified (99%) requirements.",Test,"System test and monitoring availability over the course of a rolling day, week, month","eso, non-functional",project_venues,uptime.feature
MDPS_L1_REQ-3,MDPS_2_REQ-102,L2,The MDPS shall track and report project and venue based costs. (Cost Reporting),"Fine grained costing reporting based on data storage, compute, and data egress",,,eso-prototype,cost_reporting,
MDPS_2_REQ-102,MDPS_2_REQ-103,L3,The cost reporting system shall track and report system costs by one or more venues,"Costing can be reported based on a single venue, multiple venues, or all venues (project wide)",Test,"System Test, Integration Test","MCP, eso-prototype",cost_reporting,venue.feature
MDPS_2_REQ-102,MDPS_2_REQ-104,L3,The cost reporting system shall track and report system costs based on functional components,"e.g. track how much the science processing system costs, analysis platform, IDEs, etc.",Test,System Test,"MCP, eso-prototype",cost_reporting,component.feature
MDPS_2_REQ-102,MDPS_2_REQ-105,L3,The cost reporting system shall track and report data storage,"Get costs, volumes associated with data being stored within the system",Test,System Test,,cost_reporting,storage.feature
MDPS_2_REQ-102,MDPS_2_REQ-106,L3,The cost reporting system shall track and report data egress,"Get costs, volumes associated with data leaving the MMDPS",Test,System Test,,cost_reporting,egress.feature
MDPS_2_REQ-102,MDPS_2_REQ-161,L3,The cost reporting system shall be generating and capable delivering reports at a specified interval,"Instead of actively monitoring cost, cost reports can be automated and delivered to various project or MMO users.",Test,System Test,"MCP, eso",cost_reporting,reporting.feature
MDPS_2_REQ-102,MDPS_2_REQ-185,L3,The cost reporting system can alert users when cost thresholds are exceeded,"ability to alert a user when &lt;TBD&gt;70, 90% of their budget has been exceeded",Test,"System Test, UAT","MCP, eso",cost_reporting,alert.feature
MDPS_L1_REQ-3,MDPS_2_REQ-107,L2,The cost modeling system shall provide tools to assist projects in cost modeling and budget exercises. (Cost Modeling),Ability to assist projects in budgeting and planning for mission costs based on their requirements.,,,eso-prototype,cost_model,
MDPS_2_REQ-107,MDPS_2_REQ-108,L3,The cost modeling system shall provide cost models to tenant projects to estimate and budget project costs,Used to inform projects of cost implications of their usage of the MDPS.,Test,"System Test, UAT",eso-prototype,cost_model,estimate.feature
,TXT-13,,Infrastructure - Core MDPS,,,,,,
MDPS_L1_REQ-4,MDPS_2_REQ-109,L2,The MDPS shall provide capabilities to operate and administer project and venue services (managed Services),"Creation of projects, project resources, and user and role management",,,eso-prototype,managed_services,
MDPS_2_REQ-109,MDPS_2_REQ-170,L3,The MDPS shall support the previous major version of managed services,"To allow flexible project usage of managed services, the MMDPS shall support the previous major version of managed services. This means the MMDPS shall update minor and patch releases for these managed services.",Demonstration,"Demonstrate availability of patch, maintenance and security fixed for multiple major versions.",eso,managed_services,
MDPS_2_REQ-109,MDPS_2_REQ-171,L3,The MDPS shall have a centralized mechanism for requesting managed service support,"Project need a defined mechanisms for requesting bug fixes, support, general QA etc. this can take the form of a JIRA service center or github issue tracker.",Test,"System Test, UAT","eso, eso-prototype",managed_services,support.feature
MDPS_2_REQ-109,MDPS_2_REQ-111,L3,MDPS managed services shall provide the means to continuously integrate and deploy MDPS software,"Update and deploy new versions of MMDPS services to project specified venues. This allows for updated managed services to progress through the software development lifecycle (develop, test, production) along side project developed code.
 
 
   
 
 
  Projects updates will be human driven (e.g. do not upgrade until the project OKs the upgrade).",Test,System Test,eso-prototype,managed_services,ci.feature
MDPS_2_REQ-109,MDPS_2_REQ-112,L3,"The MDPS shall provide a mechanism for storing, updating, and retrieving sensitive software configuration","A way of storing and sharing configuration information across a MDPS venue. This could be database passwords, deployment credentials. An implementation would be something like the AWS systems manager security store or Hashicorp Vault like functionalities.",Test,System Test,eso-prototype,managed_services,configuration.feature
MDPS_2_REQ-109,MDPS_2_REQ-113,L3,The MDPS shall provide the capability to manage software artifacts,Artifacts required for the deployment of managed services shall also follow a MDPS CM process,Test,System Test,,managed_services,artifacts.feature
MDPS_2_REQ-109,MDPS_2_REQ-110,L3,MDPS managed services shall provide a common deployment mechanism,"Common deployment mechanism for managed services. E.g. a dashboard or API for requesting service deployments to a venue. The same dashboard or API can be used for all MMDPS services within a single venue.
 
 
   
 
 
  Deployments will be centered on widely available deployment technologies like terraform.",Test,"System Test, Integration Test",eso-prototype,managed_services,common_deployment.feature
MDPS_2_REQ-109,MDPS_2_REQ-114,L3,MDPS managed services shall provide a common upgrade mechanism,Managed services can be updated by project venue administrators,Test,"System Test, Integration Test",,managed_services,common_upgrade.feature
MDPS_2_REQ-109,MDPS_2_REQ-115,L3,"MDPS managed services shall provide a common rollback mechanism, except where prohibited by other requirements and policies","Roll back when an error is encountered during deployment should be standardized. This means an error in deployment can be detected, and the previous state can be made available to the users. Examples of implementation of this would be blue/green deployments.
 
 
   
 
 
  Exceptions to this capability would include not allowing rollbacks due to security issues, or other NASA policies.",Test,"System Test, Integration Test",eso-prototype,managed_services,common_rollback.feature
MDPS_2_REQ-109,MDPS_2_REQ-116,L3,MMDPS managed services shall provide a common destroy mechanism,Managed services can be destroyed by project venue administrators,Test,"System Test, Integration Test",,managed_services,common_destroy.feature
MDPS_2_REQ-109,MDPS_2_REQ-117,L3,"MDPS managed services shall have a user interface for deployment, monitoring, upgrading, and destruction",A dashboard for UI based management,Test,"System Test, UAT",eso-prototype,managed_services,mgmt_ui.feature
MDPS_2_REQ-109,MDPS_2_REQ-118,L3,MDPS managed services will support scheduling changes in project defined maintenance windows,Ability to schedule _when_ management activities can occur,Test,"System Test, UAT",,managed_services,mgmt_scheduling.feature
MDPS_2_REQ-109,MDPS_2_REQ-119,L3,"MDPS managed services shall provide a common mechanism for responding to security prompts (patches, AMI updates, vulnerabilities in libraries)","Maintenance requirements for time-critical activities.
 
 
   
 
 
  SPLs requiring patching of systems shall be made available to users within some pre-determined amount of time. these can be 7 days or 30 day turn around times.",Demonstration,,,managed_services,
MDPS_2_REQ-109,MDPS_2_REQ-158,L3,MDPS managed services shall allow resource customization,"Managed services need to be able to support the project use cases. This could be high CPU or Memory usage, specific storage needs, network requirements. These should be configurable where applicable (e.g. cloud resource customization).",Test,"System Test, UAT","eso, eso-prototype",managed_services,resource_customization.feature
MDPS_2_REQ-109,MDPS_2_REQ-159,L3,MDPS managed services shall report health metrics,"Managed services need to report on health metrics- these can be customized for each project, but should include things like uptime, request latency, resource usage, etc.",Test,System Test,"eso, eso-prototype",managed_services,managed_health.feature
MDPS_2_REQ-109,MDPS_2_REQ-172,L3,MDPS managed services shall notify users of available updates,A way of identifing manages services with updates available for supported versions.,Test,System Test,"MCP, eso",managed_services,mgmt_update_availability.feature
MDPS_2_REQ-109,MDPS_2_REQ-173,L3,MDPS managed services shall notify users of pending and in-progress deployments,Users are alerted to pending upgrades in services through some mechanisms,Test,System Test,eso,managed_services,mgmt_notify_deployments.feature
MDPS_2_REQ-109,MDPS_2_REQ-181,L3,MDPS managed service deployment can be monitored for status and deployment issues.,Ability to monitor a deployment of a managed service,Test,"System Test, UAT",eso,managed_services,mgmt_deployment_status.feature
MDPS_2_REQ-109,MDPS_2_REQ-182,L3,MDPS managed services shall be automatically validated upon deployment or rollback,Key to ensuring working software,Test,"System Test, Integration Test, Smoke Test",eso,managed_services,managed_deployment_validation.feature
MDPS_2_REQ-109,MDPS_2_REQ-196,L3,MDPS managed services shall be capable of alerting users based on health metrics,"Alerts based on uptime, availability, high or low resource usage, etc.",Test,System Test,eso,managed_services,mgmt_health_alerts.feature
MDPS_2_REQ-109,MDPS_2_REQ-208,L3,The MDPS shall generate a manifest of deployment services,"Required for redeployment of a given venue, promotion of a tested venue, and provenance tracking",Test,system test,,managed_services,mgmt_manifest.feature
MDPS_2_REQ-109,MDPS_2_REQ-207,L3,The MDPS shall be capable of deploying one or more services based on a previously generated deployment manifest,"Required to reproduce a given environment, especially valuable in dev-< test-> ops lifecycles, as well as for provenance.",Test,System Test,,managed_services,mgmt_manifest_clone.feature
MDPS_2_REQ-109,MDPS_2_REQ-220,L3,The MDPS should mitigate infrastructure vendor lock in by enabling MDPS capabilities be deployed in multiple environments,"Vendor lock-in here is targeting the hosting platform- either cloud (e.g. AWS, GCP, Azure), On-premise, or HPC. The MDPS system should avoid dependency on specific hosting technologies where reasonably capable. This is a Should (goal) of the system, as there may be times where reliance on specific hosting technology has a counterpart in other environments or when platform interfaces are standardized between environments.",Demonstration,,eso,managed_services,
MDPS_L1_REQ-4,MDPS_2_REQ-120,L2,The MDPS shall comply with NASA Accessibility And Cyber Security requirements.,,,,eso-prototype,security,
MDPS_2_REQ-120,MDPS_2_REQ-121,L3,The MDPS shall be Section 508 compliant,accessibility requirements: (accessibility. see https://www.section508.gov/manage),Test,"System Test, UAT",,security,508.feature
MDPS_2_REQ-120,MDPS_2_REQ-122,L3,The MDPS shall implement measures to prevent user created malicious code and data from being shared within the MDPS.,Algorithms and workflows will be scanned for vulnerabilities prior to being cataloged and stored within the MDPS.,Test,System Test,MCP,security,malicious_code.feature
MDPS_2_REQ-120,MDPS_2_REQ-123,L3,The MDPS shall comply with NASA institutional security requirements as specified in NASA-SPEC-2600 v2.4,The platform on which MDPS runs will have its own specific security constraints (e.g. AWS Cloud on MCP vs JPL AWS cloud vs GovCloud). This is a blanket requirement to capture the need to comply.,Test,System Test,"MCP, eso-prototype",security,compliance.feature
MDPS_2_REQ-120,MDPS_2_REQ-124,L3,The MDPS shall encrypt all data at rest,NASA Requirement for data encryption at rest,Test,System Test,"MCP, eso-prototype",security,encryption.feature
MDPS_2_REQ-120,MDPS_2_REQ-125,L3,The MDPS mission stores shall secure and allow for monitoring of data as specified in NASA-SPEC-2600 v2.4,"Secure may involve 'encrypt at rest data' or provide 'auditing' features. This becomes much more robust if itar, EAR, etc data become a part of the MMDPS process, in which case the venue containing the storage might exist in GovCloud, on premise, or omewhere else.",Test,System Test,"MCP, eso-prototype",security,data.feature
MDPS_2_REQ-120,MDPS_2_REQ-211,L3,The MDPS shall be EAR99/ITAR/EAR compliant.,Missions using MDPS will require export control for some of their Software applications/Software implementation. This requirement will ensure that the MDPS architecture will comply with ITAR/EAR.,,,MCP,security,ear.feature
MDPS_L1_REQ-4,MDPS_2_REQ-126,L2,"All services within MDPS shall be robust, available","service requirements that enable the usage of the MMDPS: up time, versioning, multi-availability zones, multi-region (where applicable).",Demonstration,,eso-prototype,availability,
MDPS_2_REQ-126,MDPS_2_REQ-127,L3,"The MDPS services shall be capable meeting or exceeding 99% availability, excluding unplanned downtime","Availability is a key feature of managed services, and is required to make design decisions for the system as a whole.
 
 
 
 Note we refer to planned downtime, not unforseen downtime to scope cost and ability to meet this requirement (e.g. 3.6 days of planned downtime a year.) 
 
 
   
 
 
  the goal of the system would be zero planned downtime. The shared services are key interfaces between venues and projects. Because they are shared services, used by many projects, finding a suitable downtime for a critical service could be an issue, but the system will have predetermined maintenance windows and alerts to possible outages.","Test,Analysis","Modeling of architecture, testing of uptime","MCP, eso-prototype",availability,managed_uptime.feature
MDPS_2_REQ-126,MDPS_2_REQ-129,L3,The MDPS shall monitor and report on service availability,a mechanism to provide the status of managed and shared services,Test,System Test,,availability,managed_monitoring.feature
MDPS_2_REQ-126,MDPS_2_REQ-130,L3,"The MDPS shall provide the current and, at minimum, 7-day historical status of MDPS service health","Provide the last 7 days of service health. Service health is defined as TBD.
 
 
   
 
 
  minimum of 7 days, but can be more.",Test,System Test,,availability,managed_monitoring_historic.feature
MDPS_2_REQ-126,MDPS_2_REQ-131,L3,The MDPS shared system shall have a published Service Level Agreement,"Need to publish an SLA for shared services:
 

  * uptime
  * availability
  * request/limits",Test,System Test,,availability,multitenant_availability_sla.feature
MDPS_2_REQ-126,MDPS_2_REQ-169,L3,"The MDPS shall be capable of being deployed in a ""High Availability"" mode","To support critical operations or reduce single points of failure, HA (High Availability) modes allow for the failure of one or more components while maintaining functionality",Test,System Test,eso,availability,high_availability.feature
MDPS_2_REQ-126,MDPS_2_REQ-209,L3,"MDPS managed services shall be capable of recovering information critical to system operations, as prescribed in a project level SLA","The ability for a managed service to operate usually requires software, configuration, and state (e.g. files, database) that must be backed up to provide mission critical functionality. While 'back up' is an implementation, the ability to recover is the needed functionality","Test,Demonstration","system test, Demo",,availability,managed_recovery.feature
MDPS_2_REQ-126,MDPS_2_REQ-336,L3,MDPS managed services shall be capable of restoring functionality after a catastrophic failure,Disaster Recovery requirement,"Test,Demonstration","System Test, active demonstrations,",eso,availability,managed_restoration.feature
MDPS_2_REQ-126,MDPS_2_REQ-210,L3,The MDPS Shared Services shall limit requests by a project venue to a specified amount as specified in shared service SLAs,"Shared services, to prevent overconsumption by a given project venue, need to be able to limit the number of requests fulfilled. The limit placed on projects is specified in the SLA. Requests above this limit may be fulfilled, but may also be denied. The calling venue needs to handle the fulfilled requests and denied requests.",Test,Testing rate limiting of componrents.,"SLA, eso",availability,multitenant_request_limiting.feature
MDPS_L1_REQ-4,MDPS_2_REQ-132,L2,Shared Services within the MDPS shall allow for customer adoption to changes in implementation,"Managed services need to be able to upgrade for performance, functionality and security reasons. This is often at odds with a project relying on a consistent, unchanging interface. The following requirement(s) allow for services to push out changes in a timely manner while not forcing the upgrade schedule on projects.",,,,,
MDPS_2_REQ-132,MDPS_2_REQ-133,L3,The MDPS shall enable tenants to upgrade interfaces within a service defined lifecycle,Shared services can roll out new functionlity via versioned (one possible implementation) interfaces. Previous interfaces will be available for some amount of time defined in a MMDPS SLA.,Demonstration,,,,
MDPS_L1_REQ-4,MDPS_2_REQ-134,L2,The MDPS shall provide the capability to manage venue resources.,"Allow for scaling, cost controls, cpu/ram types",Test,System Test,,,
MDPS_2_REQ-134,MDPS_2_REQ-135,L3,The MDPS shall remain within a priori budget constraints,"Allow for a setup that will not exceed a pre-defined budget, broken down by 'service areas'. The system cannot run without some form of cost controls. Either MMDPS or the project using MMDPS ultimately needs to pay a bill if using some form of unbounded cost (e.g the cloud). We must place an artificial bound on the system to prevent running over a budget given to us by a project. MMDPS itself must have a budget, consisting of all the other projects plus some overhead (possibly).",Test,System Test,MCP,,
MDPS_L1_REQ-4,MDPS_2_REQ-136,L2,The MDPS shall provide user management capabilities for MDPS and MDPS project administrators (User Management),"User management includes user identification, role and permissions, and project/venue relationships to allow or restrict for access to MMDPS and project resources",,,eso-prototype,user_management,
MDPS_2_REQ-136,MDPS_2_REQ-137,L3,The MDPS shall require all users to login.,"in order to enforce project and user based permissions, all users shall login to the system.
 
 
   
 
 
  MFA is a l4 or a security requirement. MfA is not why we need this requirement above (e.g. being able to restrict access to various artifacts/services based on user).",Test,System Test,eso-prototype,user_management,login.feature
MDPS_2_REQ-136,MDPS_2_REQ-138,L3,The user management system shall provide a common authentication mechanism,"A common interface to authentication would enable the same mechanism regardless of user point of entry, as well as centralize the addition/removal' of users. This will also facilitate authorization, roles, permissions, sharing, etc. across the service areas.",Test,"System Test, Integration Test",eso-prototype,user_management,authn.feature
MDPS_2_REQ-136,MDPS_2_REQ-139,L3,The user management system shall provide a common authorization mechanism,Used across all MMDPS services regardless of authenntication maechanisms,Test,System Test,eso-prototype,user_management,authz.feature
MDPS_2_REQ-136,MDPS_2_REQ-140,L3,The user management system shall provide the capability to add and remove users from authorization roles,Roles provide permissions via the adding and removal of users to roles,Test,System Test,eso-prototype,user_management,add_remove_user_from_roles.feature
MDPS_2_REQ-136,MDPS_2_REQ-141,L3,The user management system shall provide the capability to add and remove authorization roles,"Functionality to add/remove users from the system, along with managing their roles and assigned permissions",Test,System Test,eso-prototype,user_management,add_remove_roles.feature
MDPS_2_REQ-136,MDPS_2_REQ-142,L3,The user management system shall provide the capability to add and remove users from the MDPS,"Add a user to the MDPS- different from having access to the AWS accounts/resource on which MDPS is running. This is the access to APIs and services and Uis (dashboards, IDEs).",Test,System Test,eso-prototype,user_management,add_remove_users.feature
MDPS_2_REQ-136,MDPS_2_REQ-143,L3,The user management system shall allow for passwordless authentication,Ability to make service requests without including/sending of the password along with the request. implementation can be SSO or something else.,Test,System Test,,user_management,passwordless.feature
,TXT-14,,Open Science,,,,,,
MDPS_L1_REQ-5,MDPS_2_REQ-145,L2,"The MDPS shall be capable of specifying the data, algorithms and environments needed to reproduce workflow executions (Workflow Provenance System)","Given these descriptions and the environment is still supporting those components (e.g. the PGE and the OS/System it was run on), a user could reproduce the science processing of a given product or set of products. This would be useful for open science, disaster recovery, and on-demand processing where configurations are changed to produce a bespoke product based on delivered science team algorithms (e.g. on-demand raster, NISAR on demand)",,,,provenance,
MDPS_2_REQ-145,MDPS_2_REQ-219,L3,The provenance system shall support asynchronous process requests,"Due to its design as a workflow item, provenance cannot be a blocking step from the workflows. As such it must be able to accept provenance requests regardless of the status of the system.",Test,System Test,eso,provenance,async.feature
MDPS_2_REQ-145,MDPS_2_REQ-146,L3,The provenance system shall maintain persistent identifiers for algorithms used in data production,algorithm is an entity in the provenance chain for a product.,Test,System Test,,provenance,algorithm_persistent_identifiers.feature
MDPS_2_REQ-145,MDPS_2_REQ-147,L3,The provenance system shall maintain persistent identifiers for workflows used in data production,"workflow is an entity in the provenance chain for a product, can be referenced from the workflow catalog",Test,System Test,,provenance,workflow_persistent_identifiers.feature
MDPS_2_REQ-145,MDPS_2_REQ-148,L3,The provenance system shall maintain records of deployments used in data production,Allow for the provenance of deployments to understand the makeup of the system and artifacts. Deployments are not stored elsewhere and so a record needs to eb created for reference,Test,System Test,,provenance,deployment_provenance.feature
MDPS_2_REQ-145,MDPS_2_REQ-149,L3,The provenance system shall maintain records of environments used in data production,"Allow for the provenance of environments (OS, instance types, etc). Environments are not stored elsewhere and so a record needs to eb created for reference",Test,System Test,,provenance,environment_provenance.feature
MDPS_2_REQ-145,MDPS_2_REQ-195,L3,The provenance system shall maintain records of ancillary and auxiliary data used in data production,Aux and Anc data may be pre-staged to workers outside of the workflow being execute (e.g. a model is available at /models). We need to ensure we're capturing this information for provenance purposes.,Test,System Test,eso,provenance,anc_aux_provenance.feature
MDPS_L1_REQ-5,MDPS_2_REQ-150,L2,The MDPS shall provide a shared provenance catalog for the registration and storage of product provenance (Data Provenance System),the implementaiton where provenance is stored,,,,provenance,
MDPS_2_REQ-150,MDPS_2_REQ-151,L3,"The data provenance system shall store product provenance, at minimum, for the life of a project.","The provenance information, or how a product was made, the inputs, and the configurations used shall be stored in the MMDPS. The requirements for provenance are defined in The MMDPS shall manage asset provenance. these should be validated by the data store before being sent to the common provenance store.",Test,System Test,,provenance,lom_product_provenance.feature
MDPS_L1_REQ-1,MDPS_2_REQ-152,L2,The MDPS shall provide the capability for users to search and access provenance in the system. (Provenance Systems),"Users does not refer to ""public"" users, but rather the logged in users of the MMDPS.",,,,provenance,
MDPS_2_REQ-152,MDPS_2_REQ-153,L3,"The provenance systems shall allow users to search by identifier, name, and relationship","find data in the system by some identifier (e.g. algorithm unique id), algorithm common name (may not be unique), or in a relationship 'used by', 'creates' etc.",Test,System Test,,provenance,search_provenance.feature
MDPS_L1_REQ-5,MDPS_2_REQ-154,L2,The MDPS shall generate and store product provenance for MDPS generated data,,,,,provenance,
MDPS_2_REQ-154,MDPS_2_REQ-155,L3,Provenance systems shall represent provenance using the WC3-Prov standard,allow standard creation/consumption and allow implementation to change behind the scenes.,Test,"System Test, Integration Test",interface,provenance,wc3-prov.feature
MDPS_L1_REQ-5,MDPS_2_REQ-197,L2,MDPS Software Development shall comply with SPD-41a,,,,eso-prototype,open_science,
MDPS_2_REQ-197,MDPS_2_REQ-198,L3,"Restricted software, as defined in SPD-41a Appendix B, shall not be made publicly available without approval through the cognizant authority.",,Test,System Test,eso-prototype,,
MDPS_2_REQ-197,MDPS_2_REQ-199,L3,"For software developed at NASA Centers and released through the NPR 2210 process, Center Intellectual Property Counsel shall be consulted in the selection of the license to be used in the release of software.",Software developed as part of the MDPS needs to appropriately licensed,Demonstration,,eso-prototype,,
MDPS_2_REQ-197,MDPS_2_REQ-200,L3,"For publicly available software projects, ESD-funded software projects shall include a code of conduct and guidelines for how to make contributions.",Required components of open-source development,Test,System Test,eso-prototype,,
MDPS_2_REQ-197,MDPS_2_REQ-201,L3,"When released as open source software, source code for ESD-funded software shall be made available in a publicly accessible repository that is widely recognized by the community.","Open sourced, shareable code needs to be in a widely accessible location.",Test,System Test,"MDPS, eso-prototype",,
MDPS_2_REQ-197,MDPS_2_REQ-202,L3,Publicly available ESD-funded software shall be reported by the developers of the software so it can be indexed as part of the NASA catalog of software.,,Demonstration,,eso-prototype,,
MDPS_2_REQ-197,MDPS_2_REQ-203,L3,Publicly available ESD-funded software shall be citable using a persistent identifier.,DOI for publicly citable code,Test,System Test,"MDPS, eso-prototype",,
MDPS_2_REQ-197,MDPS_2_REQ-204,L3,"New technologies, including software, developed under ESD funding shall be reported to NASA at invention.nasa.gov.",,Demonstration,,eso-prototype,,
MDPS_2_REQ-197,MDPS_2_REQ-205,L3,"Mission software shall be developed openly in a publicly accessible, version-controlled platform that allows for contributions and engagement from the community.",,Test,System Test,eso-prototype,,
MDPS_2_REQ-197,MDPS_2_REQ-206,L3,"To achieve reproducibility, scientific software developed using ESD funding and used in support of a scientific, peer-reviewed publication shall be released as open source software no later than the publication date.","Includes MDPS softawre but also workflow and application packages developed by ESD funded projects.
 
 
   
 
 
  requires a way of delivering software (applicaiton packages- code, containers, descriptions) to archive facilities at time of data production (might be during or after mission processing).",Test,System Test,,,